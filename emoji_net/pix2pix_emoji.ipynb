{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='data/'\n",
    "raw_data_dir=data_dir+'raw/'\n",
    "\n",
    "def get_img(i,target_size):\n",
    "    import imageio, skimage\n",
    "    x = imageio.imread(raw_data_dir+'data_'+str(i)+'_x.jpg',as_gray=True).astype(np.float)\n",
    "    x = scipy.misc.imresize(x, target_size)\n",
    "    x= np.stack((x,)*1, -1)\n",
    "    x = x/127.5 - 1.\n",
    "    \n",
    "    y = imageio.imread(raw_data_dir+'data_'+str(i)+'_y.jpg', as_gray=True).astype(np.float)\n",
    "    y = scipy.misc.imresize(y, target_size)\n",
    "    y= np.stack((y,)*1, -1)\n",
    "    y = y/127.5 - 1.\n",
    "\n",
    "    return x,y\n",
    "\n",
    "def load_images(target_size):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    img_files = [f for f in listdir(raw_data_dir) if isfile(join(raw_data_dir, f)) and '_x.jpg' in f]\n",
    "    n_x=len(img_files)\n",
    "    X=np.zeros((n_x,target_size[0], target_size[1], target_size[2]))\n",
    "    Y=np.zeros((n_x,target_size[0], target_size[1], target_size[2]))\n",
    "    \n",
    "    for i in range(n_x):\n",
    "        x,y =get_img(i,target_size)\n",
    "        X[i,:,:,:] = x\n",
    "        Y[i,:,:,:] = y\n",
    "    return X,Y,n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE https://github.com/eriklindernoren/Keras-GAN\n",
    "\n",
    "def build_generator(input_shape,gf,name):\n",
    "    \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "    n_H, n_W, n_C = input_shape\n",
    "    def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = BatchNormalization(momentum=0.8)(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u\n",
    "\n",
    "    # Image input\n",
    "    d0 = Input(shape=input_shape)\n",
    "\n",
    "    # Downsampling\n",
    "    d1 = conv2d(d0, gf, bn=False)\n",
    "    d2 = conv2d(d1, gf*2)\n",
    "    d3 = conv2d(d2, gf*4)\n",
    "    d4 = conv2d(d3, gf*8)\n",
    "    d5 = conv2d(d4, gf*8)\n",
    "    d6 = conv2d(d5, gf*8)\n",
    "    d7 = conv2d(d6, gf*8)\n",
    "\n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d7, d6, gf*8)\n",
    "    u2 = deconv2d(u1, d5, gf*8)\n",
    "    u3 = deconv2d(u2, d4, gf*8)\n",
    "    u4 = deconv2d(u3, d3, gf*4)\n",
    "    u5 = deconv2d(u4, d2, gf*2)\n",
    "    u6 = deconv2d(u5, d1, gf)\n",
    "\n",
    "    u7 = UpSampling2D(size=2)(u6)\n",
    "    output_img = Conv2D(n_C, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "    return Model(d0, output_img,name=name)\n",
    "\n",
    "def build_discriminator(input_shape, df, name):\n",
    "    \n",
    "    n_H, n_W, n_C = input_shape\n",
    "    def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    img_A = Input(shape=input_shape)\n",
    "    img_B = Input(shape=input_shape)\n",
    "\n",
    "    # Concatenate image and conditioning image by channels to produce input\n",
    "    combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "    d1 = d_layer(combined_imgs, df, bn=False)\n",
    "    d2 = d_layer(d1, df*2)\n",
    "    d3 = d_layer(d2, df*4)\n",
    "    d4 = d_layer(d3, df*8)\n",
    "\n",
    "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "    return Model([img_A, img_B], validity, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, gf=64, df=64, name='pix2pix_emoji'):\n",
    "    n_H, n_W, n_C = input_shape\n",
    "    # Calculate output shape of D (PatchGAN)\n",
    "    patch = int(n_H / 2**4)\n",
    "    disc_patch = (patch, patch, 1)\n",
    "\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_discriminator(input_shape,df,'model_discriminator')\n",
    "    #-------------------------\n",
    "    # Construct Computational\n",
    "    #   Graph of Generator\n",
    "    #-------------------------\n",
    "    # Build the generator\n",
    "    generator = build_generator(input_shape,gf,'model_generator')\n",
    "\n",
    "    # Input images and their conditioning images\n",
    "    img_A = Input(shape=input_shape)\n",
    "    img_B = Input(shape=input_shape)\n",
    "\n",
    "    # By conditioning on B generate a fake version of A\n",
    "    fake_A = generator(img_B)\n",
    "\n",
    "    # For the combined model we will only train the generator\n",
    "    \"\"\"By setting trainable=False after the discriminator has been compiled the discriminator \n",
    "    is still trained during discriminator.train_on_batch but since it's set to non-trainable \n",
    "    before the combined model is compiled it's not trained during combined.train_on_batch.\"\"\"\n",
    "    # discriminator.trainable = False\n",
    "\n",
    "    # Discriminators determines validity of translated images / condition pairs\n",
    "    valid = discriminator([fake_A, img_B])\n",
    "\n",
    "    combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A], name=name)\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,imgs_A, imgs_B, epochs=1, batch_size=1):\n",
    "       \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    m, n_H, n_W, n_C = imgs_A.shape\n",
    "    \n",
    "    # Calculate output shape of D (PatchGAN)\n",
    "    patch = int(n_H / 2**4)\n",
    "    disc_patch = (patch, patch, 1)\n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((m,) + disc_patch)\n",
    "    fake = np.zeros((m,) + disc_patch)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    # Condition on B and generate a translated version\n",
    "    fake_A = model.get_layer(\"model_generator\").predict(imgs_B)\n",
    "    # Train the discriminators (original images = real / generated = Fake)\n",
    "    model.get_layer(\"model_discriminator\").trainable= True\n",
    "    d_loss_real = model.get_layer(\"model_discriminator\").fit(x=[imgs_A, imgs_B], y=valid, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    d_loss_fake = model.get_layer(\"model_discriminator\").fit(x=[fake_A, imgs_B], y=fake, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    d_loss = 0.5 * np.add(d_loss_real.history['loss'], d_loss_fake.history['loss'])\n",
    "\n",
    "    # -----------------\n",
    "    #  Train Generator\n",
    "    # -----------------\n",
    "    # Train the generators. SET Discriminator trainable false.\n",
    "    model.get_layer(\"model_discriminator\").trainable= False\n",
    "    g_loss = model.fit(x=[imgs_A, imgs_B], y=[valid, imgs_A], batch_size=batch_size, epochs=epochs)\n",
    "    elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "    return model,g_loss,d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(generator, imgs_A, imgs_B,epoch):\n",
    "    m, n_H, n_W, _ = imgs_A.shape\n",
    "    figsize=(n_H,n_W)\n",
    "    generated_A = generator.predict(imgs_B)\n",
    "    \n",
    "    titles = ['Original', 'Generated', 'Condition']\n",
    "    fig, axs = plt.subplots(m, len(titles),figsize=figsize)\n",
    "    for r in range(m):\n",
    "        axs[r,0].imshow(imgs_A[r,:,:,0], cmap='gray')\n",
    "        axs[r,0].set_title(titles[0])\n",
    "        axs[r,0].axis('off')\n",
    "        axs[r,1].imshow(generated_A[r,:,:,0], cmap='gray')\n",
    "        axs[r,1].set_title(titles[1])\n",
    "        axs[r,1].axis('off')\n",
    "        axs[r,2].imshow(imgs_B[r,:,:,0], cmap='gray')\n",
    "        axs[r,2].set_title(titles[2])\n",
    "        axs[r,2].axis('off')\n",
    "    fig.savefig(\"output/pix2pix_epoch_%d.png\" % (epoch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape=[256,256,1]\n",
    "X,Y,n_x = load_images(input_shape)\n",
    "if False:\n",
    "    print(X.shape)\n",
    "    i_sample=np.random.randint(n_x)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "    ax1.imshow(X[i_sample,:,:,0], cmap=\"gray\")\n",
    "    ax2.imshow(Y[i_sample,:,:,0], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model_filepath=None):\n",
    "    if model_filepath is None :\n",
    "        model=build_model(input_shape,name='model_combined')\n",
    "    else :\n",
    "        model = load_model(model_filepath)\n",
    "        \n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    model.get_layer('model_discriminator').compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "    model.compile(loss=['mse', 'mae'], loss_weights=[1, 100],optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "m, _, _, _ = X.shape\n",
    "_s=np.random.randint(m-5)\n",
    "X_sample=X[_s:_s+5,:,:,:]\n",
    "Y_sample=Y[_s:_s+5,:,:,:]\n",
    "model_filepath='saved_model/pix2pix_emoji_model__epoch_last.h5'\n",
    "\n",
    "model=get_compiled_model()\n",
    "#model = load_model(model_filepath)\n",
    "for i in range(0, 3):\n",
    "    model,_,_=train_epoch(model,X, Y, epochs=1, batch_size=16)\n",
    "    model.save(filepath=model_filepath,overwrite=True)\n",
    "    sample_images(model.get_layer('model_generator'),X_sample, Y_sample,i)\n",
    "    model = get_compiled_model(model_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
